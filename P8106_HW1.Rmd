---
title: "P8106_HW1"
author:
- "Naomi Simon-Kumar"
- ns3782
date: "2/16/2025"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

```

## Loading libraries

```{r libraries}

library(ISLR)
library(glmnet)
library(caret)
library(tidymodels)
library(corrplot)
library(ggplot2)
library(plotmo)
library(ggrepel)

```

## Question (a): Lasso Model

To start, we load the training and testing data and subsequently set a seed for reproducibility.

Next, we initialise 10-fold cross-validation to partition the training data into 10 equal subsets. This allows training the model on 9 folds while validating on the final fold. This ensures we evaluate the performance of the model, while avoiding overfitting.

```{r Qa_data_prep}

# Load training and testing data

training_data <- read.csv("housing_training.csv")
testing_data <- read.csv("housing_test.csv")

set.seed(29)  # Ensure results are reproducible

# Using 10 fold cross-validation

ctrl1 <- trainControl(method = "cv", number = 10)

```

Next, we proceed to fit a lasso regression model using the training data. Sale_Price is the outcome variable, with all other variables as predictors. The lasso model is tuned over a sequence of 100 lambda values ranging from exp(6) to exp(-5).

```{r Qa_lasso_fit}

set.seed(29)  # Ensure results are reproducible

# Fit the Lasso model

lasso.fit  <- train(
  Sale_Price ~ .,
  data = training_data,
  method = "glmnet",
  tuneGrid = expand.grid(alpha = 1, 
                         lambda = exp(seq(6, -5, length = 100))),
  trControl = ctrl1
)

# Plot

plot(lasso.fit, xTrans = log)

```

Based on the plot, it appears as though the optimal lambda value is around exp(4), as this is where the RMSE is minimised. Higher lambda values (i.e., greater penalisation) appear to result in poorer model performance, likely due to excessive shrinkage forcing too many coefficients to zero, leading to underfitting.

```{r}

set.seed(29)  # Ensure results are reproducible

# Find optimal tuning parameter

lasso.fit$bestTune

# Extracting coefficients for each predictor, at the optimal lambda

coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda)

```

Note that at the optimal lambda value, most of the predictors remain in the model. However, some are shrunk to zero (i.e., Second_Flr_SF, Fireplace_QuGood) during the variable selection process, and removed from the model. Therefore, this final model includes **37 predictors**.

```{r}

set.seed(29)  # Ensure results are reproducible

# Finding RMSE

lasso_preds <- predict(lasso.fit, newdata = testing_data)  
rmse <- sqrt(mean((lasso_preds - testing_data$Sale_Price)^2))
print(rmse)

```

For the lasso model, the optimal tuning parameter lambda is **68.18484**, representing where RMSE is minimised. The test error (RMSE) at this lambda is **20969.2**.

```{r}

set.seed(29)  # Ensure results are reproducible

# Using 1se cross-validation. 
# Code from: https://www.rdocumentation.org/packages/caret/versions/6.0-92/topics/oneSE

ctrl_1se <- trainControl(
  method = "cv",
  selectionFunction = "oneSE"  
)

# Fit the lasso model using 1se

lasso_1se_fit <- train(
  Sale_Price ~ .,
  data = training_data,
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = 1,
    lambda = exp(seq(6, -5, length = 100))  
  ),
  trControl = ctrl_1se
)

# Optimal lambda using 1SE 

lasso_lambda_1se <- lasso_1se_fit$bestTune$lambda
print(lasso_lambda_1se)

# Extracting coefficients for each predictor, at the optimal lambda

coef(lasso_1se_fit$finalModel, s = lasso_lambda_1se)

```

Using the 1SE rule, the optimal lambda is **403.4288**. During the variable selection process, variables Second_Flr_SF, Fireplace_QuNo_Fireplace, and Exter_QualGood are removed from the model.
When the 1SE rule is applied, there are **36 predictors** included in the model, which is 1 fewer than the original lasso model.

## Question (b): Elastic Net

To fit the elastic net model, I began with a wide lambda range.

```{r}

# Set seed to ensure reproducibility

set.seed(16)

# Fit elastic net model
# Tuning the different lambda ranges

enet.fit <- train(Sale_Price ~ .,
                  data = training_data,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21), 
                                         lambda = exp(seq(6, -5, length = 100))),
                  trControl = ctrl1)

# Results

print(enet.fit$bestTune)

# Cross validation plot

plot(enet.fit, xTrans = log)

```

After reviewing the cross-validation plot, I refined the lambda range.

```{r}

# Set seed to ensure reproducibility

set.seed(16)

# Adjusting

enet.fit <- train(Sale_Price ~ .,
                  data = training_data,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21), 
                                         lambda = exp(seq(5.7, -2, length = 100))),
                  trControl = ctrl1)

# Cross validation plot

plot(enet.fit, xTrans = log)

# Optimal lambda

print(enet.fit$bestTune)

```

The cross validation plot shows the RMSE values were fairly stable at lower regularisation values, but increasing steeply when log(lambda) â‰ˆ 6. Therefore, the selected tuning parameters are **alpha = 0.1** and **lambda = 298.8674**.

```{r}

# Set seed to ensure reproducibility

set.seed(16)

# Predictions using testing dataset

enet.pred <- predict(enet.fit, newdata = testing_data)

# Test error

test_mse <- mean((enet.pred - testing_data$Sale_Price)^2)

# Results

print(test_mse)

```

From this, the test error of the model is **440832286**.





